---
permalink: /
title: About Me
excerpt: "Homepage"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a third-year Ph.D. student at the Department of Computer Science and Engineering, [The Chinese University of Hong Kong (CUHK)](https://www.cuhk.edu.hk/chinese/index.html), advised by Prof. [Michael R. Lyu](http://www.cse.cuhk.edu.hk/lyu/home). I got my Master's degree from Harbin Institute of Technology Shenzhen in June 2023, under the supervision of Prof. [Cuiyun Gao](https://cuiyungao.github.io/). Before that, I received my Bachelor's degree from Harbin Institute of Technology Weihai in June 2021. My research interests mainly focus on code intelligence and large language models.


<div style='display: none'>
My research mainly focuses on software engineering and code intelligence. Code Intelligence leverages artificial intelligence techniques to analyze and generate source code, which could benefit a variety of software engineering activities and tasks such as program repair, defect detection, code summarization, etc. Besides, I also have a wide interest in the development of code intelligence models in real-world scenarios and the development of Large Language Models (LLMs) for software engineering. Specifically, my research interest lies in the span of the following topics:

1. Code analysis and generation: code representation learning, code generation, static analysis

2. Code intelligence in real-world scenarios: robustness, data imbalance, continual learning

3. LLM for software engineering: in-context learning, chain of thought, tool using
</div>




#  News
- *2025.11* ðŸŽ‰ðŸŽ‰ One Paper "ContextPilot: Code Context Engineering with Memory-Augmented Exploration Agents" is accepted by LLM4Code 2026!
- *2025.10* ðŸŽ‰ðŸŽ‰ One Paper "SEER: Enhancing Chain-of-Thought Code Generation through Self-Exploring Deep Reasoning" is accepted by ICSE 2026!
- *2025.04* ðŸŽ‰ðŸŽ‰ Our Paper "Search-Based LLMs for Code Optimization" win <font color="#FF0000 ">ACM SIGSOFT Distinguished Paper Award!</font>
- *2025.04* ðŸŽ‰ðŸŽ‰ Two Paper "Beyond PEFT: Layer-Wise Optimization for More Effective and Efficient Large Code Model Tuning" and "RAG or Fine-tuning? A Comparative Study on LCMs-based Code Completion in Industry"  are accepted by FSE 2025 and FSE 2025 industry track!
- *2024.08* ðŸŽ‰ðŸŽ‰ One Paper "A Systematic Evaluation of Large Code Models in API Suggestion: When, Which, and How" is accepted by ASE 2024!
- *2024.07* ðŸŽ‰ðŸŽ‰ One Paper "Search-Based LLMs for Code Optimization" is directly accepted by ICSE 2025 without revision, with an acceptance rate of 8.8% (46/523)!
- *2024.03* ðŸŽ‰ðŸŽ‰ One Paper "SCALE: Constructing Symbolic Comment Trees for Software Vulnerability Detection" is accepted by ISSTA 2024!
- *2023.12* ðŸŽ‰ðŸŽ‰ One Paper "Learning in the Wild: Towards Leveraging Unlabeled Data for Effectively Tuning Pre-trained Code Models" is accepted by ICSE 2024!
- *2023.07* ðŸŽ‰ðŸŽ‰ One Paper "What Makes Good In-context Demonstrations for Code Intelligence Tasks with LLMs?" is accepted by ASE 2023! 
- <div style='display: none'>
- *2023.06* ðŸŽ‰ðŸŽ‰ One Paper "Domain Knowledge Matters: Improving Prompts with Fix Templates for Repairing Python Type Errors" is accepted by ICSE 2024!
- *2022.12* ðŸŽ‰ðŸŽ‰ Two papers "Two Sides of the Same Coin: Exploiting the Impact of Identifiers in Neural Code Comprehension" and "Keeping Pace with Ever-Increasing Data: Towards Continual Learning of Code Intelligence Models" are accepted by ICSE 2023!
</div>

# Selected Publications 

- **[LLM4Code'26]** ContextPilot: Code Context Engineering with Memory-Augmented Exploration Agents     
_**Shuzheng Gao**_, Chaozheng Wang, Shuqing Li, Yun Peng and Michael R. Lyu \| [[Paper]](../files/contextpilot.pdf)     

- **[ICSE'26]** SEER: Enhancing Chain-of-Thought Code Generation through Self-Exploring Deep Reasoning   <font color="#FF0000 ">(CCF-A)</font>  
_**Shuzheng Gao**_, Chaozheng Wang, Cuiyun Gao and Michael R. Lyu \| [[Paper]](https://arxiv.org/abs/2510.17130) \| [[Code]](https://github.com/shuzhenggao/ICSE26SEER)

- **[ICSE'25]** Search-Based LLMs for Code Optimization   <font color="#FF0000 ">(CCF-A)</font>  
_**Shuzheng Gao**_, Cuiyun Gao, Wenchao Gu and Michael R. Lyu \| [[Paper]](https://arxiv.org/abs/2408.12159) \| [[Code]](https://github.com/shuzhenggao/sbllm) \|

- **[ICSE'24]** Learning in the Wild: Towards Leveraging Unlabeled Data for Effectively Tuning Pre-trained Code Models   <font color="#FF0000 ">(CCF-A)</font>  
_**Shuzheng Gao**_, Wenxin Mao, Cuiyun Gao, Li Li, Xing Hu, Xin Xia and Michael R. Lyu  \| [[Paper]](https://arxiv.org/abs/2401.01060) \| [[Code]](https://github.com/shuzhenggao/HINT) 

- **[ASE'23]** What Makes Good In-context Demonstrations for Code Intelligence Tasks with LLMs?   <font color="#FF0000 ">(CCF-A)</font>  
_**Shuzheng Gao**_, Xin-Cheng Wen, Cuiyun Gao, Wenxuan Wang, Hongyu Zhang and Michael R. Lyu \| [[Paper]](https://arxiv.org/abs/2304.07575) \| [[Code]](https://github.com/shuzhenggao/ICL4code) 

- **[ICSE'23]** Two Sides of the Same Coin: Exploiting the Impact of Identifiers in Neural Code Comprehension   <font color="#FF0000 ">(CCF-A)</font>  
_**Shuzheng Gao**_, Cuiyun Gao, Chaozheng Wang, Jun Sun, David Lo and Yue Yu \| [[Paper]](https://arxiv.org/abs/2207.11104) \| [[Code]](https://github.com/ReliableCoding/CREAM) 

- **[ICSE'23]** Keeping Pace with Ever-Increasing Data: Towards Continual Learning of Code Intelligence Models   <font color="#FF0000 ">(CCF-A)</font>  
_**Shuzheng Gao**_, Hongyu Zhang, Cuiyun Gao and Chaozheng Wang \| [[Paper]](https://arxiv.org/abs/2209.07027) \| [[Code]](https://github.com/ReliableCoding/REPEAT) 

- **[TOSEM'23]** Code Structure Guided Transformer for Source Code Summarization   <font color="#FF0000 ">(CCF-A)</font>  
_**Shuzheng Gao**_, Cuiyun Gao, Yulan He, Jichuan Zeng, Lun Yiu Nie, Xin Xia and Michael R. Lyu \| [[Paper]](https://arxiv.org/abs/2104.09340) \| [[Code]](https://github.com/gszsectan/SG-Trans)   

# Selected Awards

- ACM SIGSOFT Distinguished Paper Award, ICSE, 2025
- Postgraduate Studentship Award, CUHK, 2023
- Distinguished Paper Award, ASE-Inch, 2023
- Best Student Paper Award, ACAIT, 2022
- Outstanding Graduates of Harbin Institute of Technology, 2021
- National Scholarship, Ministry of Education, 2019

<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=C6tYBi-zUAcUjn0-KFJV1KaftFhTp2GrOlPaCdmIs9c&cl=ffffff&w=a"></script>
